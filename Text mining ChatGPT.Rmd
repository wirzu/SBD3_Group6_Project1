---
title: "Text mining ChatGPT"
author: "Abishan, Josua, Lars, Luca"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

##Introduction Beschriebung einfügen über Projekt. \## Load packages and data

```{R}
library (syuzhet)
library (stringr)
library (tidyverse)
library (ggplot2)
library(scales)
library(stringi)
library(lubridate)
library(dplyr)
options(scipen=999)

load("ChatGPT.rda")
```

## 1. Question: What can you tell us about the users that tweet about ChatGPT?

```{R}
# Creating a copy of tweets
tweets_orig <- tweets

# take unique users
Users <- tweets[4:10]
Users = Users[!duplicated(Users$User),]

# Calculating average lenght of tweet
char_counts <- nchar(tweets$Tweet)
av_char_count <- mean(char_counts)
rounded_avg_char_count <- round(av_char_count, 2)
# tabelle einfügen mit rounded_avg_char_count!!!!!

#create median
retweets_median = median(Users$Retweets)
retweets_mean = mean(Users$Retweets)

likes_median = median(Users$Likes)
likes_mean = mean(Users$Likes)

Friends_median = median(Users$UserFriends)
Friends_mean = mean(Users$UserFriends)

Followers_median = median(Users$UserFollowers)
Followers_mean = mean(Users$UserFollowers)

verified_median = median(Users$UserVerified)
verified_mean = mean(Users$UserVerified)

# Create a tibble with the values
my_table <- tibble(
  Statistik = c("Retweets", "Likes", "Friends", "Followers", "Verified"),
  Median = c(retweets_median, likes_median, Friends_median, Followers_median, verified_median),
  Average = c(retweets_mean, likes_mean, Friends_mean, Followers_mean, verified_mean)
)

print(my_table)
```
Hier Erklärung Tabelle einfügen. (Joshi)

```{R}
#Average/ median of Hour when to tweet, Nr of Retweets, Likes, Followers, Friends, verified

#create Histogramm for Tweettime
plot_dataHour <- tweets %>% 
  group_by (timeofday_hour) %>%
  count()

ggplot (plot_dataHour, 
        aes (x=timeofday_hour, y=n)) +
  geom_bar(stat = "identity")+
  theme_minimal () +
  ggtitle("Number of tweets over time (per hour)") +
  xlab("Hour") +
  ylab("Number of tweets")
```
Hier Erklärung Grafik einfügen. (Joshi)

```{R}
#Number of tweets tweeted of an user
#range breaks
range_breaks <- c(0, 100, 500, 1500, 5000, 15000000)

#Appling cut() on follower-data
Users$range <- cut(Users$UserFollowers, breaks = range_breaks)

Users <- na.omit(Users)

# Creating Barplot
ggplot(Users, aes(x = range, fill = range)) + geom_bar() + labs(title = "Number of Twitter-Follower", x = "Range", y = "Number of users")
# Beschriftung x Achse auf numerisch wechseln !!!!!!
```
Hier Erklärung Grafik einfügen. (Joshi)

```{R}
#number of tweets over time
plot_data <- tweets %>% 
  group_by (tweet_date) %>%
  count()

ggplot (plot_data, 
        aes (x=tweet_date, y=n)) +
  geom_bar(stat = "identity")+
  theme_minimal () +
  ggtitle("Number of reviews over time (per day)") +
  xlab("Date 22/23") +
  ylab("Number of tweets")
```
Hier Erklärung Grafik einfügen. (Joshi)
```{R}
# Convert UserCreated to datetime format
Users$UserCreated <- ymd_hms(Users$UserCreated)

# Create the plot
ggplot(Users, aes(x = UserCreated)) + 
  geom_histogram(bins = 50, fill = "#69b3a2", color = "#e9ecef") +
  labs(x = "Account Creation Date", y = "Number of Accounts") +
  ggtitle("Twitter Account Creation Dates")

```
Hier Erklärung Grafik einfügen. (Joshi)

## 2. What are the tweets about, what do users associated the new technology with (e.g. industries, specific applications, and also emotions)?

## Pre processing

```{R}
# Define a function to preprocess the text
preprocess_text <- function(text) {
  
  # Convert text to lower case
  text <- tolower(text)
  
  # Remove emojis and emoticons
  text <- gsub("[\U0001F600-\U0001F64F\U0001F910-\U0001F96F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]", "", text, perl=TRUE)
  
  # Remove numbers
  text <- gsub("\\d+", "", text)
  
  # Remove punctuation
  text <- gsub("[[:punct:]]", "", text)
  
  # Remove whitespace
  text <- gsub("\\s+", " ", text)
  
  # Remove stopwords and other words to be removed
  words_to_remove <- c("the", "and", "in", "to", "a", "of")
  words_to_remove_pattern <- paste0("\\b(", paste(words_to_remove, collapse = "|"), ")\\b")
  text <- gsub(words_to_remove_pattern, "", text, ignore.case = TRUE)
  
  # Return the preprocessed text
  return(text)
}

# Apply the preprocessing function to the Tweet column
tweets$preprocessed_text <- sapply(tweets$Tweet, preprocess_text)

```
Erklärung zu pr Prozessing, bzw. was wir entfernt haben. (Absichtlich nicht buchstaben sonder Füllwörter entfernt)
```{R}

### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
### STEP 3: PERFORM AUTOMATED CONTENT ANALYSIS
### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

#Select text column and create your custom dictionary
tweets$dic1 <- "NA"
tweets$dic1 <-str_count(tweets$preprocessed_text, "design|color|black|looks")
tweets$dic2 <-str_count(tweets$preprocessed_text, "bad|dislike|waste|don't")
tweets$dic3 <-str_count(tweets$preprocessed_text, "bad|dislike|waste|dont")
tweets$dic2_occurence<-ifelse(tweets$dic2>=2,1,0)
tweets$dic3_occurence<-ifelse(tweets$dic3>=2,1,0)
tweets$dic1_occurence<- "NA"
#select threshold for occurence of the topic
tweets$dic1_occurence<-ifelse(tweets$dic1>=2,1,0)
#number of reviews that cover topic
sum (tweets$dic1_occurence)
sum(tweets$dic2_occurence)

## VISUALIZE RESULTS
#sum of reviews that cover topic per day
plot_data <- tweets %>% 
  group_by (tweet_date) %>%
  summarise(n_content=sum(dic3_occurence))

ggplot (plot_data, aes (x=tweet_date, y=n_content)) + geom_bar(stat = "identity")+ theme_minimal () + ggtitle("Number of reviews covering the topic (per month)")
```

```{R}
### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
### STEP 4: PERFORM SENTIMENT ANALYSIS
### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

#Select text column and calculate sentiment scores. You can change the method (e.g."syuzhet", "bing", "nrc")
tweets$sentiment <- "NA"
tweets$sentiment <- get_sentiment(tweets$preprocessed_text, method="syuzhet", lang="english")

## VISUALIZE RESULTS
# mean over time
plot_data <- tweets %>% 
  group_by (tweet_date) %>%
  summarise(n_sentiment=mean(sentiment))

ggplot (plot_data, aes (x=tweet_date, y=n_sentiment)) + geom_line()+ theme_minimal () + ggtitle("Sentiment scores over time (mean per month)")



```
